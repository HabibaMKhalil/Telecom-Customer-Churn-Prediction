# -*- coding: utf-8 -*-
"""Customer_Churn_Prediction_Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1FOkTlr-f6bZC4m-740tGEO6_VpdEZ_r8

# Predicting Customer Churn in Telecommunications

# Group :
### Lujain Ahmad 202201738 - Mai Waheed 202200556 - Zeina Ayman 202200351 - Farida Mohamed 202202579 - Habiba Khalil 202200720
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.compose import ColumnTransformer
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, classification_report, roc_curve

train = pd.read_csv("train.csv")
train.head()

print(train.info())

print(train.isnull().sum())

print(train.duplicated().sum())

# We can convert all the non numerical values into numerical values using LabelEncoder
Le = LabelEncoder()
train['state'] = Le.fit_transform(train['state'])
train['area_code'] = Le.fit_transform(train['area_code'])
train['international_plan'] = Le.fit_transform(train['international_plan'])
train['voice_mail_plan'] = Le.fit_transform(train['voice_mail_plan'])
train['churn'] = Le.fit_transform(train['churn'])

# Define X (features) and y (target)
X = train.drop(columns = ["churn"])
y = train["churn"]
X_train, X_val, y_train, y_val = train_test_split(X,y,test_size = 0.2,random_state = 42)

print('Class distribution before SMOTE:')
print(train['churn'].value_counts())

# Apply SMOTE to balance the dataset
from imblearn.over_sampling import SMOTE
# Initialize SMOTE
smote = SMOTE(random_state = 42)
X_train_smote, y_train_smote = smote.fit_resample(X_train,y_train)
# Display class distribution after SMOTE
print('Class distribution after SMOTE:')
print(y_train_smote.value_counts())

# Feature Engineering Example
train['total_full_day_minutes'] = train['total_day_minutes'] + train['total_eve_minutes'] + train['total_night_minutes']
train['total_full_day_calls'] = train['total_day_calls'] + train['total_eve_calls'] + train['total_night_calls']
train['total_full_day_charge'] = train['total_day_charge'] + train['total_eve_charge'] + train['total_night_charge']

# Drop the original columns now represented by derived features
columns_to_drop = ["total_day_minutes","total_eve_minutes","total_night_minutes","total_day_calls","total_eve_calls","total_night_calls","total_day_charge","total_eve_charge","total_night_charge"]
train = train.drop(columns = columns_to_drop)

print(train.duplicated().sum())

print(train.isnull().sum())

train.head()

# Train Decision Tree
decision_tree = DecisionTreeClassifier(random_state = 42)
decision_tree.fit(X_train_smote,y_train_smote)
# Train Random Forest
random_forest = RandomForestClassifier(random_state = 42,n_estimators = 100)
random_forest.fit(X_train_smote,y_train_smote)
# Train Naive Bayes
nb_model = GaussianNB()
nb_model.fit(X_train_smote,y_train_smote)
# Train SVM
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train_smote)
X_val_scaled = scaler.transform(X_val)
svm_model = SVC(kernel = 'rbf',probability = True,random_state = 42)
svm_model.fit(X_train_scaled,y_train_smote)
# Predict on Validation Set
y_val_pred_tree = decision_tree.predict(X_val)
y_val_pred_rf = random_forest.predict(X_val)
y_val_pred_nb = nb_model.predict(X_val)
y_val_pred_svm = svm_model.predict(X_val_scaled)
# Predict Probabilities for ROC-AUC
y_val_proba_tree = decision_tree.predict_proba(X_val)[:,1]
y_val_proba_rf = random_forest.predict_proba(X_val)[:,1]
y_val_proba_nb = nb_model.predict_proba(X_val)[:,1]
y_val_proba_svm = svm_model.predict_proba(X_val_scaled)[:,1]
# Evaluate Models
def evaluate_model(y_true,y_pred,y_proba):
    accuracy = accuracy_score(y_true,y_pred)
    precision = precision_score(y_true,y_pred)
    recall = recall_score(y_true,y_pred)
    auc_roc = roc_auc_score(y_true,y_proba)
    print(f"Accuracy: {accuracy:.2f}")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"AUC-ROC: {auc_roc:.2f}")
    print("\nClassification Report:\n")
    print(classification_report(y_true,y_pred))
print("Decision Tree Performance:")
evaluate_model(y_val,y_val_pred_tree,y_val_proba_tree)
print("______________________________________________________")
print("\nRandom Forest Performance:")
evaluate_model(y_val,y_val_pred_rf,y_val_proba_rf)
print("______________________________________________________")
print("\nNaïve Bayes Performance:")
evaluate_model(y_val,y_val_pred_nb,y_val_proba_nb)
print("______________________________________________________")
print("\nSupport Vector Machine (SVM) Performance:")
evaluate_model(y_val,y_val_pred_svm,y_val_proba_svm)

# Plot ROC Curve
def plot_roc_curve(y_true,y_proba,label):
    fpr,tpr,_ = roc_curve(y_true,y_proba)
    plt.plot(fpr,tpr,label = f"{label}(AUC = {roc_auc_score(y_true,y_proba):.2f})")
plt.figure(figsize = (10,6))
plot_roc_curve(y_val,y_val_proba_tree,"Decision Tree")
plot_roc_curve(y_val,y_val_proba_rf,"Random Forest")
plot_roc_curve(y_val, y_val_proba_nb, "Naïve Bayes")
plot_roc_curve(y_val, y_val_proba_svm, "SVM")
plt.plot([0,1],[0,1],'k--',label = "Random Guess")
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curve")
plt.legend()
plt.show()

# Grouping data by 'state' to analyze total and churn counts
temp_df = train.groupby("state")["churn"].agg(['count','sum']).rename(columns = {'count':'total_orders','sum':'total_churns'})
temp_df = temp_df.sort_values('total_orders',ascending = False).reset_index()
# Visualizing the most popular states with total orders and churns
fig, ax = plt.subplots(figsize = (10,7))
ax = sns.barplot(y = temp_df.state[0:20],x = temp_df.total_orders[0:20],color = 'darkgray',label = "Total Orders")
ax = sns.barplot(y = temp_df.state[0:20],x = temp_df.total_churns[0:20],color = 'r',label = "Total Churns")
# Adjusting labels and title
ax.set_ylabel("State")
ax.set_xlabel("Total Orders")
ax.set_title("Most Active States and Churn Counts")
ax.legend(loc = 4,prop = {'size':12})
plt.show()

# Visualize churn counts by state
plt.figure(figsize = (12,8))
train['state'].value_counts().plot(kind = 'bar',color = 'crimson')
plt.title('Churn Counts by State')
plt.xlabel('State')
plt.ylabel('Number of Customers')
plt.xticks(rotation = 45)
plt.show()

plt.figure(figsize = (10,8))
sns.heatmap(train.corr(),annot = True,cmap = 'coolwarm',fmt = '.2f')
plt.title('Correlation Matrix')
plt.show()

# Check for Overfitting
def check_overfitting(model,X_train,y_train,X_val,y_val):
    from sklearn.metrics import accuracy_score
    # Predict on training and validation sets
    y_train_pred = model.predict(X_train)
    y_val_pred = model.predict(X_val)
    # Calculate accuracies
    train_acc = accuracy_score(y_train,y_train_pred)
    val_acc = accuracy_score(y_val,y_val_pred)
    print("Training Accuracy:",train_acc)
    print("Validation Accuracy:",val_acc)
    if train_acc - val_acc > 0.1:
        print("Warning: Model may be overfitting.")
    else:
        print("No significant overfitting detected.")
check_overfitting(random_forest,X_train,y_train,X_val,y_val)

# Testing
test = pd.read_csv("test.csv")
# Preprocessing: Apply Label Encoding as in training
Le = LabelEncoder()
test['state'] = Le.fit_transform(test['state'])
test['area_code'] = Le.fit_transform(test['area_code'])
test['international_plan'] = Le.fit_transform(test['international_plan'])
test['voice_mail_plan'] = Le.fit_transform(test['voice_mail_plan'])
test_features = test.drop(columns = ["id"])
predictions = random_forest.predict(test_features)
# Save predictions
output = pd.DataFrame({"id": test["id"],"churn": predictions})
output.to_csv("test_predictions.csv",index = False)
print("Predictions saved to test_predictions.csv")

test_pred = pd.read_csv("test_predictions.csv")
test_pred.head()